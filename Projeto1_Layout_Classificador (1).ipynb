{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\lucca\\Desktop\\Projeto1_ciencia_dados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'netflix1.2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>namoral as serie da hbo max pisa samba rebola ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @xd_xandao: @gaguinho001 porra tlgd kkkkkkk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @___dudasilvaa: eu e juan vimos todos os fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com a cria√ß√£o destes streaminga doa est√∫dios d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gosto da amazon prime, mais tem tanta s√©rie qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  classifica√ß√£o\n",
       "0  namoral as serie da hbo max pisa samba rebola ...              1\n",
       "1  rt @xd_xandao: @gaguinho001 porra tlgd kkkkkkk...              1\n",
       "2  rt @___dudasilvaa: eu e juan vimos todos os fi...              0\n",
       "3  com a cria√ß√£o destes streaminga doa est√∫dios d...              1\n",
       "4  gosto da amazon prime, mais tem tanta s√©rie qu...              0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @notthatindigo: sim, eu me garanto sem filt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leitores morrem ap√≥s n√£o receber nenhuma propo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@netflixbrasil se vc tirar naruto vc me paga n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faltou o loirinho pra assistir netflix cmg #askbf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>netflix se as personagens s√£o portugueses n√£o ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  classifica√ß√£o\n",
       "0  rt @notthatindigo: sim, eu me garanto sem filt...              0\n",
       "1  leitores morrem ap√≥s n√£o receber nenhuma propo...              0\n",
       "2  @netflixbrasil se vc tirar naruto vc me paga n...              1\n",
       "3  faltou o loirinho pra assistir netflix cmg #askbf              0\n",
       "4  netflix se as personagens s√£o portugueses n√£o ...              1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "**O produto escolhido foi a plataforma de streaming de filmes e s√©ries, Netflix. Para esse projeto, consideramos como relevantes \n",
    "quaisquer tweets que mencionassem a marca netflix e t√≠tulos atrelados √† ela, incluindo: Cr√≠ticas √† plataforma, compara√ß√µes com \n",
    "concorrentes, elogios √† plataforma e cr√≠ticas e elogios direcionados √† s√©ries presentes no cat√°logo pela netflix.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      rt @___dudasilvaa: eu e juan vimos todos os fi...\n",
       "4      gosto da amazon prime, mais tem tanta s√©rie qu...\n",
       "6          hoje eu s√≥ queria netflix, pipoca e chocolate\n",
       "8      @rafinhabastos tenho netflix, youtube premium ...\n",
       "9      rt @geglobo: pvc: minist√©rio p√∫blico diz que p...\n",
       "                             ...                        \n",
       "287    @jorge95782476 @vulcanreporter @universodcnaut...\n",
       "288    rt @mutualmeendes: ter um show completo em 4k ...\n",
       "295              chuva, netflix e pipoca.. s√≥ faltou ele\n",
       "298    @bancointer botei netflix e spotify no banco d...\n",
       "299    @geil41608112 n√£o diz nada, √© s√≥ que esse home...\n",
       "Name: Treinamento, Length: 152, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train = train.Treinamento\n",
    "\n",
    "tweet_train_rel = train.loc[train['classifica√ß√£o']== 1,:]\n",
    "tweet_train_rel = tweet_train_rel.Treinamento\n",
    "\n",
    "\n",
    "\n",
    "tweet_train_irrel = train.loc[train['classifica√ß√£o']== 0,:]\n",
    "tweet_train_irrel = tweet_train_irrel.Treinamento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "netflix    293\n",
       "a          155\n",
       "e          139\n",
       "de         131\n",
       "que        131\n",
       "          ... \n",
       "esfor√ßa      1\n",
       "p√°scoa       1\n",
       "maioria      1\n",
       "baixar       1\n",
       "of           1\n",
       "Length: 1947, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for texto in tweet_train:\n",
    "    \n",
    "    tweet_raw = cleanup(texto.lower()).split()\n",
    "    #tweets += \" \"+tweet_raw\n",
    "    \n",
    "    for palavra in tweet_raw:\n",
    "        if palavra != 'rt':\n",
    "            tweets.append(palavra)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "\n",
    "#Total de palavras contando todos os tweets\n",
    "print(len(tweets))\n",
    "\n",
    "tweets_tot_serie = pd.Series(tweets)\n",
    "\n",
    "# aqui √© so olhar o lenght que ja da pra saber o numero de palavras totais sem repeti√ß√£o, pra usar no Laplace\n",
    "tweets_tot_serie.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2824\n"
     ]
    }
   ],
   "source": [
    "tweets_rel = []\n",
    "for texto in tweet_train_rel:\n",
    "    \n",
    "    tweet_raw = cleanup(texto.lower()).split()\n",
    "    #tweets += \" \"+tweet_raw\n",
    "    \n",
    "    for palavra in tweet_raw:\n",
    "        if palavra != 'rt':\n",
    "            tweets_rel.append(palavra)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "#Total de palavras contando os tweets RELEVANTES(leva em conta palavras repetidas)\n",
    "print(len(tweets_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix     143\n",
       "a            78\n",
       "de           73\n",
       "que          62\n",
       "e            61\n",
       "           ... \n",
       "parece        1\n",
       "suspense      1\n",
       "demais        1\n",
       "üëèüèªüôèüèª          1\n",
       "recusada      1\n",
       "Length: 1131, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_rel_serie = pd.Series(tweets_rel)\n",
    "\n",
    "tweets_rel_serie.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2903\n"
     ]
    }
   ],
   "source": [
    "tweets_irrel = []\n",
    "for texto in tweet_train_irrel:\n",
    "    \n",
    "    tweet_raw = cleanup(texto.lower()).split()\n",
    "    #tweets += \" \"+tweet_raw\n",
    "    \n",
    "    for palavra in tweet_raw:\n",
    "        if palavra != 'rt':\n",
    "            tweets_irrel.append(palavra)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "#Total de palavras contando os tweets IRRELEVANTES(leva em conta palavras repetidas)\n",
    "print(len(tweets_irrel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix      150\n",
       "e             78\n",
       "a             77\n",
       "que           69\n",
       "de            58\n",
       "            ... \n",
       "watch          1\n",
       "0ü§°             1\n",
       "escpecial      1\n",
       "msm            1\n",
       "of             1\n",
       "Length: 1158, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_irrel_serie = pd.Series(tweets_irrel)\n",
    "\n",
    "tweets_irrel_serie.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
